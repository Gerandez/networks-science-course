{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 04: Networks from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will learn to construct a network from a set of implicit relationships. The relationships that we will study are between accounts in Twitter, a micro-blogging service.\n",
    "\n",
    "We will create two networks: one directed and one undirected.\n",
    "\n",
    "* In the **directed mention network**, we will say that there is a link of weight *w* from account *x* to account *y*, if account *x* has re-tweeted (re-posted) or mentioned *w* times account *y*.\n",
    "\n",
    "* In the **undirected co-mention network**, we will say that there is a link of weight *w* between accounts *x* and *y*, if both accounts have been mentioned together in *w* tweets.\n",
    "\n",
    "The input material you will use is a file named `CovidLockdownCatalonia.json.gz` available in the [data/](data/) directory. This is a gzip-compressed file, which you can de-compress using the `gunzip` command. The file contain about 35,500 messages (\"tweets\") posted between March 13th, 2020, and March 14th, 2020, containing a hashtag or keyword related to COVID-19, and posted by a user declaring a location in Catalonia.\n",
    "\n",
    "The tweets are in a format known as [JSON](https://en.wikipedia.org/wiki/JSON#Example). Python's JSON library takes care of translating it into a dictionary.\n",
    "\n",
    "**How was this file obtained?** This file was obtained from the [CrisisNLP](https://crisisnlp.qcri.org/covid19). This is a website that provides COVID-19 collections of tweets, however, they only provide the identifier of the tweet, known as a tweet-id.\n",
    "\n",
    "To recover the entire tweet, a process commonly known as *re-hydration* needs to be used, which involves querying an API from Twitter, giving the tweet-id, and obtaining the tweet. This can be done with a little bit of programming or using a software such as [twarc](https://github.com/DocNow/twarc#dehydrate).\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Your name here</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">Your e-mail here</font>\n",
    "\n",
    "Date: <font color=\"blue\">The current date here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Code snippets you may need\n",
    "\n",
    "## 0.1. Iterating through tweets on disk\n",
    "\n",
    "We do not need to uncompress this file (it is about 236 MB uncompressed, but only 31 MB compressed).\n",
    "\n",
    "```python\n",
    "with gzip.open(COMPRESSED_INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    for line in input_file:\n",
    "        tweet = json.loads(line)\n",
    "        author = tweet[\"user\"][\"screen_name\"]\n",
    "        message = tweet[\"full_text\"]\n",
    "        print(\"%s: '%s'\" % (author, message))\n",
    "```\n",
    "\n",
    "If instead you want to open it in uncompressed, first `gunzip` the file and then do:\n",
    "\n",
    "```python\n",
    "with io.open(INPUT_FILENAME, \"r\", encoding=\"utf-8\") as input_file:\n",
    "```\n",
    "\n",
    "The rest of the code stays the same.\n",
    "\n",
    "*Tip*: place all the `import` commands in a single cell at the top of your notebook.\n",
    "\n",
    "## 0.2. Extracting mentions\n",
    "\n",
    "What we need now is a function to extract mentions, so that if we give, for instance `RT @Jordi: check this post by @Xavier`, it returns the list `[\"Jordi\", \"Xavier\"]`.\n",
    "\n",
    "This is such function:\n",
    "\n",
    "```python\n",
    "def extract_mentions(text):\n",
    "    return re.findall(\"@([a-zA-Z0-9_]{5,20})\", text)\n",
    "```\n",
    "\n",
    "Note that you will need an `import re` command must be at the beginning of the file, together with the other imports. You may need to execute the cell that contains the import by pressing `Shift-Enter` on it.\n",
    "\n",
    "You can now print all the links between accounts by doing:\n",
    "\n",
    "```python\n",
    "mentions = extract_mentions(message)\n",
    "for mention in mentions:\n",
    "    print(\"%s mentioned %s\" % (author, mention))\n",
    "```\n",
    "\n",
    "## 0.3. Counting mentions\n",
    "\n",
    "To count how many times a mention happen, you will keep a dictionary:\n",
    "\n",
    "```python\n",
    "mentions_counter = {}\n",
    "```\n",
    "\n",
    "Each key in the dictionary will be a tuple `(author, mention)` where `author` is the username of the person who writes the message, and `mention` the username of someone who is mentioned in the message. To update the dictionary, use this code while you are reading the input file:\n",
    "\n",
    "```python\n",
    "for mention in mentions:\n",
    "    key = (author, mention)\n",
    "    if key in mentions_counter:\n",
    "        mentions_counter[key] += 1\n",
    "    else:\n",
    "        mentions_counter[key] = 1\n",
    "```\n",
    "\n",
    "## 0.4. Writing a CSV file\n",
    "\n",
    "To write a CSV file, assuming you created the ``mentions_counter`` data structure above:\n",
    "\n",
    "```python\n",
    "with io.open(OUTPUT_FILENAME, \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter='\\t', quotechar='\"')\n",
    "    writer.writerow([\"Source\", \"Target\", \"Weight\"])\n",
    "    for key in mentions_counter:\n",
    "        author = key[0]\n",
    "        mention = key[1]\n",
    "        weight = mentions_counter[key]\n",
    "        writer.writerow([author, mention, weight])\n",
    "```\n",
    "\n",
    "## 0.5. Iterating through all co-mentions\n",
    "\n",
    "Suppose mentions in a Tweet are in the array ``mentions``, then you can iterate through all pairs of co-mentioned like this:\n",
    "\n",
    "```python\n",
    "for mention1 in mentions:\n",
    "    for mention2 in mentions:\n",
    "        if mention1 < mention2:\n",
    "            key = (mention1, mention2)\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The directed mentions network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the **directed mention network**, which has a weighted edge (source, target, weight) if user *source* mentioned user *target* at least once; with *weight* indicating the number of mentions.\n",
    "\n",
    "Create two files: one containing all edges, and one containing all edges having *count* greater or equal than 2.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave only one of these two following lines, then remove this comment\n",
    "INPUT_FILENAME = \"CovidLockdownCatalonia.json\"\n",
    "COMPRESSED_INPUT_FILENAME = \"CovidLockdownCatalonia.json.gz\"\n",
    "\n",
    "OUTPUT_ALL_EDGES_FILENAME = \"CovidLockdownCatalonia.csv\"\n",
    "OUTPUT_FILTERED_EDGES_FILENAME = \"CovidLockdownCatalonia-min-weight-filtered.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to create the directed mention network; your code can span multiple cells</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mentions network visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the filered edge file in Cytoscape, by importing its CSV file. You may have to set the delimiter to \"Tab\" in the advanced options, when importing.\n",
    "\n",
    "The file is large so if you want to see all details while zooming out you may have to set ``View > Always show Graphic Details``. Note this makes the program run slower.\n",
    "\n",
    "Keep only the largest connected component, deleting the rest of the nodes (you can hold shift while drawing a rectangle, to select some nodes).\n",
    "\n",
    "Style the network:\n",
    "\n",
    "* Run \"Tools > Analyze Network ...\" (as a directed graph)\n",
    "* Style nodes by setting their size proportional to their in-degree\n",
    "* Style edges by setting their width and color (darker=more) using the *weight* attribute.\n",
    "\n",
    "Run the ClusterMaker2 plug-in to create a clustering (affinity propagation clustering) of this graph using the *weight* edge attribute. Color nodes according to their cluster, using a discrete mapping. Note that if you right-click on \"Mapping type\" when creating a discrete mapping, you can use an automatic mapping generator that you can fine-tune later.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the image as mentions.png and replace this cell with \\!\\[Mentions graph\\]\\(mentions.png\\) to display your graph.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Results Panel of the network analyzer. There is interesting information here, particularly the node degree distribution, but you can also find information such as characteristic path length, average degree, etc.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the degree distribution as mentions-degree-distribution.png and replace this cell with \\!\\[Mentions graph degree distribution\\]\\(mentions-degree-distribution.png\\) to display it.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell by a brief commentary, in your own words, of what you see in this graph. What type of graph is it? Who are the largest-degree nodes in the graph? Is there something interesting in the network analysis results? What else can you say about this graph?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The undirected co-mention network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CO_MENTIONS_FILENAME = \"CovidLockdownCatalonia-co-mentions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **undirected co-mention network** connects two accounts if they are both mentioned in the same tweet. The weight of the edge is the number of tweets in which the accounts are co-mentioned.\n",
    "\n",
    "Create new code to generate the co-mention network by modifying the previous code (make a copy of those cells so you can keep your old code, too). Remember your code should not try to load tweets in memory, just iterating through the tweets on disk.\n",
    "\n",
    "Write this to the file ``OUTPUT_CO_MENTIONS_FILENAME`` using the CSV writer, similarly to as we did before.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to create the undirected co-mentions network; your code can span multiple cells</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-mentions network visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Style the network so that line widths are larger for edges with large weights, and node sizes are larger for nodes with large degrees. Remember you need to run the network analyzer first.\n",
    "\n",
    "Use ``Layout > Prefuse Force Directed Layout > All Nodes > Weight`` to create a layout by edge weight.\n",
    "\n",
    "Run the ClusterMaker2 plug-in to create a clustering of this graph using the *Weight* attribute as weight. Use the resulting clusters to color the nodes.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the image as co_mentions.png and replace this cell with \\!\\[Co-mentions graph\\]\\(co_mentions.png\\) to display it.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell by a brief commentary, in your own words, of what you see in this graph. What type of graph is it? Who are the largest-degree nodes in the graph? How do you compare this against the directed mentioned graphs, e.g., with respect to the nodes of larger degree or that are more central? Is there something interesting in the network analysis results? What else can you say about this graph?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELIVER (individually)\n",
    "\n",
    "Remember to read the section on \"delivering your code\" in the [course evaluation guidelines](https://github.com/chatox/networks-science-course/blob/master/upf/upf-evaluation.md).\n",
    "\n",
    "Deliver a zip file containing:\n",
    "\n",
    "* This notebook\n",
    "* The mentions ``.csv`` file\n",
    "* The co-mentions ``.csv``file\n",
    "\n",
    "## Extra points available\n",
    "\n",
    "For more learning and extra points, create a network of hashtags (e.g., #COVID19), in which two hashtags are connected by an edge if they appear in the same tweet. Draw only the top hashtags, those that appear in many tweets. Include in your zip file the .csv file and in this notebook your code and the drawing of the network.\n",
    "\n",
    "**Note:** if you go for the extra points, add ``<font size=\"+2\" color=\"blue\">Additional results: hashtags graph included</font>`` at the top of your notebook.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
